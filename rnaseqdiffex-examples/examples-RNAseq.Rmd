---
title: "RNA-seq examples"
author: Paul Pavlidis and Keegan Korthauer
date: February 2021
output:
  html_document:
    toc: true
    toc_float: true
    fig_width: 6
    fig_height: 5
    keep_md: true
---

# Introduction

This file provides code, context and additional information related to the STAT540 lectures on RNA-seq analysis.

Among other things it shows how to run differential expression analysis on RNA-seq data sets using a variety of methods. We'll get a sense at how the results differ across methods, though obviously doing this on a single data set is not a real evaluation. The example data set is the same "Gompers" Chd8 mutant data set we used for lecture 3 ("exploration"). 

# Setup

First we'll make sure the necessary packages are installed. If any of the following are not installed on your system, please run the corresponding lines of code from the code chunk below (currently set to `eval = FALSE`).

```{r dependencies, eval=FALSE}
library(BiocManager)
install("tidyverse")
install("limma")
install("DESeq2")
install("edgeR")
install("pheatmap")
install("qvalue")
install("GGally")
install("UpSetR")
```

Next, we'll load these libraries and set some plotting defaults.

```{r setup, message=FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(limma)
library(DESeq2)
library(edgeR)
library(pheatmap)
library(qvalue)
library(GGally)
library(UpSetR)

bcols<-colorRampPalette(c("#000000" ,"#800000" ,"#FF8000" ,"#FFFF00", "#FFFFFF"))(20)
# Set some defaults for ggplot2.
theme_set(theme_bw(base_size = 16))
theme_update(panel.grid.major = element_blank(), panel.grid.minor = element_blank())
```

# Preparing for analysis

## Loading and preparing data

We will use the same dataset as we used in the [exploratory data analysis lecture](https://stat540-ubc.github.io/lectures/lectures_2021/lect03-eda.html#1), which was also explored in the [companion document](https://github.com/STAT540-UBC/STAT540-UBC.github.io/blob/master/examples/exploration-examples/explore.md). This is the data from [Gompers et al., 2017](https://www.ncbi.nlm.nih.gov/pubmed/28671691), that is available on GEO, at [Accession GSE99331](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE99331). However, note that this data is only available as RPKM values, *not* raw counts. As raw counts are preferable for differential expression analysis, Paul obtained these counts directly from the authors in Jan 2018. 

Note that we are using a corrected version of the meta-data obtained from the authors that fixes the miscoded sex for P0 animals.

As in the lecture 3 example, following the nomenclature of the authors, "Group" indicates the Chd8 genotype (wild type or heterozygous mutant), "DPC" indicates "Days post conception" (developmental stage).

First, we'll read in the metadata, and recode the categorical variables as factors with meaningful levels - so we don't have to remember whether `Sex = 1` refers to male or female.

```{r loadingcode}
m <- read.csv("nn.4592-S4.fixed.csv") %>%
   mutate(Sample = Sample.ID) %>%
   column_to_rownames(var = "Sample.ID") %>%
   select(-Number)

m <- m %>% 
   dplyr::rename(DPC = `Stage..DPC.`,
                 Sex = `Sex..1.male.`,
                 Group = `Group..1.WT.`,
                 SeqRun = `SeqRun`,
                 MappedReads = `Mapped.Reads`,
                 FeatureCounts = `Feature.Counts`) %>%
   mutate(Sex = factor(Sex, labels = c("M", "F")),
          Group = factor(Group, labels = c("WT", "Mu")),
          SeqRun = factor(SeqRun),
          DPC = factor(DPC))
```

Next, we'll read in the feature counts.

```{r}
counts <- read.table("Gompers_NN_CountMatrix.txt", 
                     header = TRUE, row.names = 1)
```

We'll check that the sample IDs in the columns of our count matrix match *exactly* the sample IDs in the rows of our metadata.
```{r}
identical(colnames(counts), rownames(m))
```

Great!

Now, we'll do some preliminary filtering to remove rows that are all zeroes (not expressed in any sample). We'll do more filtering later.

```{r}
dim(counts)
counts <- counts %>% filter(rowSums(.) > 0)
dim(counts)
```

### Sequencing space

Here we examine the "soaker" genes (just looking at the most extreme case).

```{r genelength}
soaker <- which.max(rowMeans(counts))
soaker

rowMeans(counts)[soaker]
```

We see that gene `r rownames(counts)[soaker]` has mean expression `r as.numeric(rowMeans(counts)[soaker])`. Let's look at a distribution of expression values across samples for this gene. 

```{r}
data.frame(count = as.numeric(counts[soaker,])) %>%
  ggplot() +
    geom_density(aes(x = count)) 
```

Next, let's look at the relationship between counts of this gene, and total number of reads in the sample.

```{r}
data.frame(count = as.numeric(counts[soaker,]),
           total = colSums(counts)) %>%
  ggplot(aes(x = count, y = total)) +
    geom_point() + 
    xlab("Rn45s raw read count") +
    ylab("Total reads in sample")
```

In some samples, this gene has over 1e6 reads - it's an outlier even relative to the sample.

Let's calculate the proportion of all reads mapping to this one gene.

```{r}
frcrn45s <- counts[soaker,]/ colSums(counts)
quantile(frcrn45s)
```

This one gene is up to `r signif(max(frcrn45s*100),2)`% of the reads! This is not unusual.

Let's look at the cumulative distribution of the number of reads per gene.

```{r}
cpgcum <- data.frame(apply(counts, 2, function(x) cumsum(sort(x))/sum(x)), 
                     index = (1:dim(counts)[1])/dim(counts)[1]) %>%
  pivot_longer(names_to = "Sample", values_to = "CumulativeFracCounts", 
               cols = -index)
ggplot(cpgcum, aes(x = index, y = CumulativeFracCounts, group = Sample)) + 
  geom_hline(yintercept = 0.5, color="grey", linetype = "dashed") + 
  geom_vline(xintercept = c(0.95), color="grey", linetype = "dashed") + 
  geom_line(show.legend = FALSE, aes(color = Sample), alpha = 0.5) +
  xlab("Proportion of genes") +
  ylab("Cumulative proportion of total counts")
```

From this we see that for most samples, the top ~5% of genes (vertical dashed line) make up approximately 50% of the counts (horizontal dashed line)!

## Counts to CPM

CPM (counts per million mapped reads) can be a useful transformation for visualization, since it removes the variation in counts among different samples that is due to the total number of reads in each sample. 

The log2 transformation is another useful transformation for visualization, since we saw in the previous section that the distribution of raw counts is right-skewed. Since counts can have a value of zero, we have to add a pseudocount before taking the log. We'll use a value of 1, so we compute log2(CPM + 1).

First we show two separate ways to compute CPM: (1) by 'hand', and (2) using `edgeR::cpm()`:

```{r}
# 1) by hand
totalReads <- colSums(counts)
cpm1 <- t(apply(counts, 1, function(x) x/totalReads*10^6))

# 2) using edgeR::cpm
cpm2 <- cpm(counts, log = FALSE, normalized.lib.sizes = FALSE)

all.equal(cpm1, cpm2)
```

Things are getting unwieldy with counts, CPM, and metadata in separate objects. Let's create a `SummarizedExperiment` object to house them all in one container. Recall that `SummarizedExperiment` is a generalization of `ExpressionSet` that allows us to store more than one expression matrix ("assay") - this will be useful for us to store both the counts and the log(CPM + 1) values.

```{r}
sumexp <- SummarizedExperiment(assays = SimpleList(counts = as.matrix(counts)), 
                             colData = DataFrame(m))

assays(sumexp)$cpm <- cpm(counts, log = FALSE, normalized.lib.sizes = FALSE)
sumexp
```

Now we can see that the raw counts are in the `counts` slot and CPM are in the `cpm` slot of `assays(sumexp)`. 

Next, we'll create a filter for lowly expressed genes. Specifically, we'll use the threshold used by the authors: only keep genes with at least 2 samples that have CPM greater than 10. 

```{r}
keep <- which(rowSums(assays(sumexp)$cpm > 10) > 2)
length(keep)  

sumexp <- sumexp[keep,]
```

Note that the filtering step subsetted both the raw counts and the CPM matrix. 

And now we'll compute log2(CPM + 1) for these filtered genes, and add to a slot we'll call `log2cpm`.

```{r}
assays(sumexp)$log2cpm <- log2(assays(sumexp)$cpm + 1)
sumexp
```

Now, let's examine the distribution of log2(CPM + 1) for our 'soaker' gene. Note that since we've filtered, we can't use the same index as before (`r as.numeric(soaker)`), so we'll subset the `SummarizedExperiment` object by the name of the soaker gene (`r names(soaker)`). 

```{r}
data.frame(log2cpm = as.numeric(assays(sumexp[names(soaker),])$log2cpm)) %>%
  ggplot() +
    geom_density(aes(x = log2cpm)) +
    xlab("log2(CPM + 1)")
```


## Setting up our design matrix 

To run a differential expression analysis, we first have to set up a design matrix. First, we decide which factors to include in the model. I want to use Group, DPC and Sex. SeqRun is confounded with DPC so I don't use it.

(Note: in the paper, they say they correct for Sex as well as both SeqRun and DPC, but in the R script they provide, they actually only use SeqRun. That does correct for both at the same time because of the confound. But I am going to use DPC anyway as the batch effect for the one time point that was run in two batches seemed minor).

tldr: We're going to use Sex, Group and DPC in the model, no interactions.

```{r modelmatrix}
modm <- model.matrix(~ Sex + Group + DPC, data = colData(sumexp))

head(modm)
```

# Differential expression analysis

## Using standard linear model

It's not unreasonable to ask whether just using standard linear models on log2(CPM + 1) would be okay. Remember the problems with this are supposed to be:

* Counts have non-normal behaviour (motivating `edgeR` and `DESeq`)
* Accounting for mean-variance effects is important (motivating limma-voom and limma-trend)
* Using moderation of the variance estimates is a good idea.

We'll see how much this matters (for this particular data set). 

In this section we'll use the base `lm` approach on log2(CPM + 1). In the next section we'll bring in the moderated t statistics (`eBayes`) and weighted regression (`voom`) and other variations on that theme, followed by the `edgeR` and `DESeq2` methods.

We are just going to keep all the results from the different runs in a data frame so we can compare them later (just the p-values for "Group").

Note: The `limma` package fits linear models efficiently _en masse_, but then adds other features that we want to see the effect of, while still using the rest of the limma workflow (e.g. `topTable`). To do so we need to turn off the extras (specifically variance shrinkage and degrees of freedom adjustment), but `limma` does not provide any built-in way to do that. Therefore, I provide some code that lets you use the usual limma workflow, but without the bells and whistles; I call it `noBayes` to replace `eBayes`. In using `noBayes` we don't get the `B` statistic so you have to specify `sort.by = "p"` in the call to `topTable`, since `sort.by="B"` is the default when examining single coefficients.

```{r regularlm}
source("noBayes.R")
lmlogcpm <- lmFit(assays(sumexp)$log2cpm, design = modm)
lmlogcpm <- noBayes(lmlogcpm) 
```

We'll print the top 10 genes by `lm` for the Sex, Group, and DPC covariates, then save the results for Group in the dataframe we'll add other results to.

```{r}
signif(topTable(lmlogcpm, number = 10, coef = "SexF", sort.by = "p"), 3)   # sex
signif(topTable(lmlogcpm, number = 10, coef = "GroupMu", sort.by = "p"), 3)   # group
signif(topTable(lmlogcpm, number =10, coef = c("DPC14.5", "DPC17.5", "DPC21", "DPC77")), 3) # DPC

# Start to collect the data from the different methods.
difmethods <- data.frame(row.names = row.names(sumexp))
difmethods$lmlogcpm <- topTable(lmlogcpm, number = Inf, coef = "GroupMu", sort.by = "none")$P.Value
```

## Using limma on log2cpm

Now we repeat, using regular `limma` with `eBayes`, as if this was a microarray data set.

```{r limma}
limmalogcpm <- lmFit(assays(sumexp)$log2cpm, design = modm)
limmalogcpm <- eBayes(limmalogcpm)
plotSA(limmalogcpm, main = "Default limma")

signif(topTable(limmalogcpm, number = 10, coef = "SexF", sort.by = "p"), 3)   # sex
signif(topTable(limmalogcpm, number = 10, coef = "GroupMu", sort.by = "p"), 3)   # group
signif(topTable(limmalogcpm, number =10, coef = c("DPC14.5", "DPC17.5", "DPC21", "DPC77")), 3) # DPC

difmethods$limmalogcpm <- topTable(limmalogcpm, number = Inf, coef = "GroupMu", 
                                   sort.by = "none")$P.Value
```

We see there's a bit of a decreasing mean-variance trend here. We'll next try out the limma-trend method to adjust for this. 

Note that the prior degrees of freedom are the extra degrees of freedom we get for using `eBayes`. 

```{r}
limmalogcpm$df.prior
```


### Bonus topic: P-value distribution

Not specifically related to RNA-seq. An essential diagnostic after doing this kind of statistical analysis is to examine the distribution of the p-values, because those p-values are used to estimate false discovery rates, which in turn depend on p-values following some sort of expected behaviour.

Options here include looking at p-value distributions (I recommend) or quantile-quantile plots of p-values. Quantile-quantile plots are also often used to examine test statistics.

```{r pvaluedists}
hist(topTable(limmalogcpm, number = Inf, coef = "SexF")$P.Value, breaks=100, 
     xlab = "P-value",
     main="Pval dist for 'Sex' (limma on logcpm)")
hist(topTable(limmalogcpm, number = Inf, coef = "GroupMu")$P.Value, breaks=100, 
     xlab = "P-value",
     main="Pval dist for 'Sex' (limma on logcpm)")
hist(topTable(limmalogcpm, number = Inf, coef = c("DPC14.5", "DPC17.5", "DPC21", "DPC77"))$P.Value,
     breaks=100, xlab = "P-value",
     main="Pval dist for 'DPC' (limma on logcpm)") 

# Instead of using pvalue histrograms, you might see QQ-plots. Here it is for 'Sex' and 'Group' 
psx <- topTable(limmalogcpm, number = Inf, coef = "SexF")$P.Value
qqplot( -log10(qunif(1-psx)), -log10(psx) , ylim=c(0,50) , xlab="expected -log10p", ylab="observed -log10p", main="QQ p for Sex (limma on cpm)", pch=20, cex=0.5)
abline(0,1, lty=3)

ps <- topTable(limmalogcpm, number = Inf, coef = "GroupMu")$P.Value
qqplot( -log10(qunif(1-ps)), -log10(ps) , ylim=c(0,15) , xlab="expected -log10p", ylab="observed -log10p", main="QQ p for Group (limma on cpm)", pch=20, cex=0.5)
abline(0,1, lty=3)

```

Compared to the histogram, the qq-plot gives a stronger impression of the deviation of the p-value distribution from the expected uniform throughout its range. The "inflation" we observe for the Chd8 genotype effect suggests *either* the effects of Chd8 are very widespread (biologically plausible) or there is a problem with our data/model resulting in inaccurate p-values (hard to know for certain, but the Sex statistics don't show this inflation).

Visualizing the p-value distributions you get a sense of how much of a "signal" there is, but this can be quantified using the `qvalue::qvalue()` method. The output `pi_0` is the estimated fraction of "true null hypotheses" while `1 - pi_0` or `pi_1` is the estimated (in this case) fraction of differentially expressed genes (with respect to the selected coefficients in the linear model we are fitting). This is useful, though wouldn't take these numbers too seriously, especially if your p-value distribution is at all "defective". You'll note that it breaks down if too many genes are differentially expressed so I don't show the call for the DPC analysis. 

```{r pi0}
# Check pi0 estimates from qvalue
1 - qvalue(topTable(limmalogcpm, number = Inf, coef = "SexF")$P.Value)$pi0
1 - qvalue(topTable(limmalogcpm, number = Inf, coef = "GroupMu")$P.Value)$pi0 # this is the one we care about

# For DPC, qvalue breaks because basically every gene is diff expr - basically 100%
1 - qvalue(topTable(limmalogcpm, Inf, coef = c("DPC14.5", "DPC17.5", "DPC21", "DPC77"))$P.Value)$pi0 

# You can also use qvalue to generate some diagnostic plots, related to p-value
# distributions and pi0
plot(qvalue(topTable(limmalogcpm, Inf, coef = "GroupMu")$P.Value))
```

For brevity's sake I'm not going to show the full p-value histograms and qvalue analyses for each of the analyses.


## Using limma-trend

Limma-trend is a modification to the standard limma approach that incorporates mean expression level as a covariate into the prior hyperparameter estimation. Its goal is to adjust for any mean-variance relationship still leftover after transformation using log CPM. Limma-trend is robust (according to the user manual) if the sequencing depth is "reasonably consistent" across samples (less than 3-fold range, which is not quite the case here - see below). Though it's worth noting that in the original voom paper, voom was a bit better than 'trend'. The way limma-trend works is the mean expression level is used as a covariate in the prior hyperparameter estimation.

```{r limmatrend}
# note that the maximum depth is more than 4-fold higher than the minimum
max(colSums(assays(sumexp)$counts)/min(colSums(assays(sumexp)$counts)))

limmatrend <- lmFit( assays(sumexp)$log2cpm, design = modm)
limmatrend <- eBayes(limmatrend, trend = TRUE) # trend=TRUE is the only diff from regular limma.
plotSA(limmatrend, main = "limma-trend") 
```

We can see the mean-variance trend estimated by limma-trend in the blue line. Next we'll examine the top ten genes by Sex, Group and DPC, as well as add the p-values for Group for the limma-trend approach to our data frame of results.

```{r}
signif(topTable(limmatrend, number = 10, coef = "SexF", sort.by = "p") ,3)
signif(topTable(limmatrend, number = 10, coef = "GroupMu", sort.by = "p") ,3)
signif(topTable(limmatrend, number = 10, coef = c("DPC14.5", "DPC17.5", "DPC21", "DPC77")),3)

difmethods$limmatrend <- topTable(limmatrend, number = Inf, coef = "GroupMu", sort = "none")$P.Value 
```

## Using limma-voom

Now we introduce the weighted regression method suggested by the limma developers to utilize the raw counts (instead of using log-transformed CPM values). Here we start to get into the mean-variance relationships (a form of heteroscedasticity) and how it can be addressed. 

Note that we are using the `counts` slot of `assays(sumexp)` now instead of the `log2cpm` slot.

```{r voom}
# voom() takes counts, NOT cpm. 
vw <- voom(assays(sumexp)$counts, design = modm, plot = TRUE, span = 0.5)  
```

We see the characteristic mean-variance relationship that the voom weights will adjust for.

```{r}
lmvoom <- lmFit(vw, modm)
lmvoom <- eBayes(lmvoom)
plotSA(lmvoom, main= "voom")
```

With the limma-voom adjustment, we see the trend between mean and variance is largely gone. 

Now we'll look at the top 10 signficant for Sex, Group, and DPC, and add the p-values for the Group coefficient to our comparison table. 

```{r}
signif(topTable(lmvoom, number = 10, coef = "SexF", sort.by = "p") ,3)
signif(topTable(lmvoom, number = 10, coef = "GroupMu", sort.by = "p") ,3)
signif(topTable(lmvoom, number = 10, coef = c("DPC14.5", "DPC17.5", "DPC21", "DPC77")),3)

difmethods$limmavoom <- topTable(lmvoom, number = Inf, coef = "GroupMu", sort = "none")$P.Value 
```

## Using limma-voom with TMM

In the previous, we use just the data without any extra normalization. The next analysis has this added (using the TMM method from `edgeR::calcNormFactors`). Later we use the same normalization approach for `edgeR`.

```{r voomnorm}
dge <- DGEList(assays(sumexp)$counts)
dge <- calcNormFactors(dge)
vwn <- voom(dge, modm )

limmavoomTMM <- lmFit(vwn, modm)
limmavoomTMM <- eBayes(limmavoomTMM)
plotSA(limmavoomTMM, main= "limma voom + TMM")

signif(topTable(limmavoomTMM, number = 10, coef = "SexF", sort.by = "p") ,3)
signif(topTable(limmavoomTMM, number = 10, coef = "GroupMu", sort.by = "p") ,3)
signif(topTable(limmavoomTMM, number = 10, coef = c("DPC14.5", "DPC17.5", "DPC21", "DPC77")),3)

difmethods$limmavoomTMM <- topTable(limmavoomTMM, number = Inf, coef = "GroupMu", 
                                    sort = "none")$P.Value 
```


## Using edgeR LRT

`edgeR` is quite a different approach than `limma` and its variants limma-trend and limma-voom. `edgeR` models the counts directly (instead of log transformed CPM values). 

### Likelihood ratio test (LRT)

`edgeR` provides two ways to do the model fitting and hypothesis testing: Likelihood ratio tests (LRT), and quasi-likelihood F-test. Starting here with the first approach. Recall that the object we created above for limma-voom (we called it `dge`) is a `DGEList` that contains the raw counts. This is the input for `edgeR`. First we add the normalization factors to the object and visualize them.

```{r edgerLR}
dge <- calcNormFactors(dge, method="TMM")

hist(dge$samples$norm.factors, breaks = 10, xlab = "Norm factor", main = "TMM Normalization factors")
```
The TMM normalization factors are values approximately centered at 1. Values less than 1 indicate that high-count genes are monopolizing the "read space". Note that if we have a large fraction (i.e. greater than 50%) differentially expressed genes, this violates the assumptions of normalization methods like TMM. 

We proceed by first estimating dispersions (recall that these are analogous to the gene-specific variances in limma), and plotting these estimates using the `plotBCV` function.

```{r}
# Estimate dispersion while automatically setting prior.df
dge <- estimateDisp(dge, design = modm, robust = TRUE)

# Check prior.df for sanity (can instead set manually with prior.df param in estimateDisp)
range(dge$prior.df)

# plot mean var trend
plotBCV(dge,  cex=0.5)
```

These estimates will be used in fitting the LRT model, which we'll do using the `glmFit` function. Then we'll pull out the top 10 genes with the `edgeR::topTags` function (similar to `topTable` in `limma`), and add the p-values for the Group covariate to our results dataframe.

```{r}
lfit <- glmFit(dge, modm)

topTags(glmLRT(lfit, coef = "SexF"))$table %>% signif(3)
topTags(glmLRT(lfit, coef = "GroupMu"))$table %>% signif(3)
topTags(glmLRT(lfit, coef = c("DPC14.5", "DPC17.5", "DPC21", "DPC77")))$table %>% signif(3)

difmethods$edgeRlrt <- topTags(glmLRT(lfit, coef = "GroupMu"), n=Inf, sort.by = "none")$table$PValue 
```

To examine see how much shrinkage we got, we'll redo the dispersion estimation, this time forcing `prior.df = 0` (no shrinkage). 

```{r}
rawd <- estimateDisp(dge, design = modm, prior.df = 0)
plotBCV(rawd, cex=0.5)
# Direct comparison
plot( sqrt(rawd$tagwise.dispersion), sqrt(dge$tagwise.dispersion) - sqrt(rawd$tagwise.dispersion),
      pch = 20, xlab = "sqrt Unshrunk disp", ylab = "difference (sqrt Shrunk - sqrt Unshrunk disp)")
abline(0,0, lty=3)
```

## Using edgeR Quasi-likelihood 

The previous section (LRT) is the  "traditional" `edgeR` approach. The newer quasi-likelihood method is generally the preferred method according to the `edgeR` documentation. It adapts approaches from limma-trend for adjusting (shrinking) the error variances (`sqeezeVar`). According to the documentation, edgeR-QL is "more conservative and rigorous" than edgeR-LR in controlling false discoveries.

Here we'll use the Quasi-likelihood approach, which is done very similarly to the traditional LRT, except using functions `glmQLFit()` and `glmQLFTest()`.

Note that we estimated dispersions the same way as before (with `estimateDisp`), except now only the trended dispersion is used under the quasi-likelihood (QL) pipeline. 

```{r edgerQL}
dge <- estimateDisp(dge, design = modm, robust = TRUE)

qfit <- glmQLFit(dge, modm)

topTags(glmQLFTest(qfit, coef = "SexF"))$table %>% signif(3)
topTags(glmQLFTest(qfit, coef = "GroupMu"))$table %>% signif(3)
topTags(glmQLFTest(qfit, coef = c("DPC14.5", "DPC17.5", "DPC21", "DPC77")))$table %>% signif(3)

difmethods$edgeRquasi <- topTags(glmQLFTest(qfit, coef = "GroupMu"), n=Inf, 
                                 sort.by = "none")$table$PValue 
```

Comparing the p-values for the LRT and QL approach, we see that both approaches give similar p-values, but the QL approach shrinks very significant values a bit less significant.

```{r, warning = FALSE}
df <- data.frame(lrt = -log10(difmethods$edgeRlrt),
                 diff = -log10(difmethods$edgeRquasi) + log10(difmethods$edgeRlrt)) 
df %>% ggplot() +
  geom_point(aes(x = lrt, y = diff), alpha = 0.1) + 
  geom_hline(yintercept = 0, linetype = "dashed", colour = "red") + 
  ylim(-3,3) + xlim(0,10) +
  xlab("-log10 p-value LRT") +
  ylab("Difference QL - LRT (-log10 pval)")
```


## Using DESeq2

Finally, we'll compare using `DESeq2`, a method similar to `edgeR` that also directly models the raw counts. 

First we have to construct a `DESeqDataSet` object. This is easy to do given a `SummarizedExperiment` object and design formula, which we already have: 

```{r deseq2}
dds <- DESeqDataSet(sumexp, modm)
dds
```
We'll compare the `DEseq` size factors to the TMM normalization factors. Note that we don't normally need to manually add the normalization size factors with `estimateSizeFactors`, because automatically run for us in the `DESeq` function, but we'll do so here so we can pull them out to compare with TMM.

```{r}
dds <- estimateSizeFactors(dds)
# double check that samples are in the same order in both edger and deseq objects
identical(colnames(dge), colnames(dds))
plot(dge$samples$norm.factors, colData(dds)$sizeFactor, pch = 20,
     xlab = "TMM normalization factors", ylab = "DESeq2 size factors")
abline(0,1, lty = 3)


plot(dge$samples$norm.factors, colSums(counts), pch = 20,
     xlab = "TMM normalization factors", ylab = "depth")

plot(colData(dds)$sizeFactor, colSums(counts), pch = 20,
     xlab = "DESeq2 size factors", ylab = "depth")
```
There's not a huge amount of agreement between the DESeq2 size factors and the TMM normalization factors. The DESeq2 factors are much more correlated with depth than TMM.

Next, we run the analysis and pull out the results table for the Group comparison (`results` is analogous to limma's `topTable` and edgeR's `topTags` functions). We'll also add those p-values to our results object. 

```{r}
dds <- DESeq(dds)

resultsNames(dds)
deseq_group <- results(dds, name = "GroupMu")

# top genes for Chd8 group
head( deseq_group[ order(deseq_group$pvalue), ] )

difmethods$deseq2 <-  deseq_group$pvalue
```

Here's an MA plot for the Group comparisons, with blue points representing genes with FDR < 0.05.

```{r}
plotMA(deseq_group, alpha = 0.05)
```

Note that `DESeq2` fails to give results for three genes (they have extreme outliers). But they are not interesting genes (high pvalues in other methods).

```{r}
difmethods[apply(difmethods, 1, function(x) any(is.na(x))),]
```

Also note that by default `DESeq2` applies Independent Filtering when computing adjusted p-values. This is different than standard FDR correction, and tends to have greater power by 'spending' the type I error according to the overall mean expression. However, it can also lead to additional genes with missing adjusted p-values (these are 'filtered' out due to low overall expression). For more info, see [this section of the DESeq2 vignette](https://bioconductor.org/packages/release/bioc/vignettes/DESeq2/inst/doc/DESeq2.html#independent-filtering-of-results). 

# Heatmaps of top genes (limma-voom)

Just showing how this is done, using the analysis we just did. As an illustration, we'll use the limma-voom results, but we could sub in any of the methods from the previous section. Note that we are displaying top genes selected by p-value. This can easily be modified to separate genes by up- and down-regulated or some other arrangement.

We'll plot the log2(CPM+1) values, and order the columns by the factor of interest first, and let the rows cluster.

```{r hm, fig.height = 6, fig.width = 10}
#  make a copy of the data ordered by the factor of interest.
sumexpS <- sumexp[, order(colData(sumexp)$Sex, colData(sumexp)$Group, colData(sumexp)$DPC)]
sumexpD <- sumexp[, order(colData(sumexp)$DPC, colData(sumexp)$Group, colData(sumexp)$Sex)]
sumexpG <- sumexp[, order(colData(sumexp)$Group, colData(sumexp)$DPC, colData(sumexp)$Sex)]

pheatmap(assays(sumexpS)$log2cpm %>% data.frame() %>%
           dplyr::filter(rownames(sumexpS) %in% rownames(topTable(limmavoomTMM, number = 30, 
                                                     coef = "SexF", sort.by = "p"))),
         scale="row", color = bcols, border_color = NA,
         cluster_cols = FALSE,
         annotation_col = colData(sumexpS)[,c("Sex", "DPC", "Group")] %>% data.frame(), 
         main = "Top genes for Sex effect (limma-voom with TMM)")

pheatmap(assays(sumexpG)$log2cpm %>% data.frame() %>%
           dplyr::filter(rownames(sumexpG) %in% rownames(topTable(limmavoomTMM, number = 30, 
                                                     coef = "GroupMu", sort.by = "p"))),
         scale="row", color = bcols, border_color = NA,
         cluster_cols = FALSE,
         annotation_col = colData(sumexpG)[,c("Group", "DPC", "Sex")] %>% data.frame(), 
         main = "Top genes for Group effect (limma-voom with TMM)")

pheatmap(assays(sumexpD)$log2cpm %>% data.frame() %>%
           dplyr::filter(rownames(sumexpD) %in% rownames(topTable(limmavoomTMM, number = 30, 
                                                     coef = c("DPC14.5", "DPC17.5", "DPC21", "DPC77"),
                                                     sort.by = "F"))),
         scale="row", color = bcols, border_color = NA,
         cluster_cols = FALSE,
         annotation_col = colData(sumexpD)[,c("DPC", "Group", "Sex")] %>% data.frame(), 
         main = "Top genes for DPC effect (limma-voom with TMM)")
```

We see the strongest visual effect with the DPC variable.

## Bonus topic: Heatmap with adjusted data (limma-trend)

Because the expression changes due to Group are small, to visualize them better we can first adjust the data for DPC, as that's a huge signal in the data. It's OK to do this as long as it's clearly indicated that it has been done. We'll use the limma-trend version of the analysis since this is carried out on the log2 CPM values, which are nice to use for visualization (as opposed to counts). In addition, we'll show how to clip the heatmap.

The estimated (fitted) effect of DPC is the fitted coefficients for DPC multiplied by the relevant part of the design matrix. We subtract that from the original data to give us our "DPC-corrected" data.

```{r adjhm, fig.height = 6, fig.width = 10}
dadj <- assays(sumexp)$log2cpm  - 
  coefficients(limmatrend)[,c("DPC14.5", "DPC17.5", "DPC21", "DPC77")] %*%
  t(modm[,c("DPC14.5", "DPC17.5", "DPC21", "DPC77")])
dadjG <- dadj[, order(colData(sumexp)$Group, colData(sumexp)$DPC, colData(sumexp)$Sex)]

# Makes it a lot easier to see the Chd8-driven pattern:
pheatmap(dadjG %>% data.frame() %>%
           dplyr::filter(rownames(sumexpG) %in% rownames(topTable(limmavoomTMM, number = 30, 
                                                     coef = "GroupMu", sort.by = "p"))),
         scale="row", 
         cluster_rows = TRUE, cluster_cols = FALSE, color = bcols, border_color = NA,
           annotation_col = colData(sumexpG)[,c("Group", "DPC","Sex" )] %>% data.frame(),
         main = "Chd8 genotype effect, Dev stage-corrected (limma-trend)")
```

Now the pattern by Group (WT vs Mutant) is a bit easier to see. 

Clipping the data (recall from our lecture on exploratory data analysis and visualization) may make it easier to visualize. It's somewhat a matter of taste; and in this case it doesn't make a huge difference. 

```{r adjhm.clip, fig.height = 6, fig.width = 10}
# Sets the minimum (-3), the maximum (3), and the increasing steps (range divided by number of colors)
# for the color scale
breaksList = seq(-3, 3, by = 6/length(bcols))

pheatmap(dadjG %>% data.frame() %>%
           dplyr::filter(rownames(sumexpG) %in% rownames(topTable(limmavoomTMM, number = 30, 
                                                     coef = "GroupMu", sort.by = "p"))),
         scale="row", breaks = breaksList,
         cluster_rows = TRUE, cluster_cols = FALSE, color = bcols, border_color = NA,
           annotation_col = colData(sumexpG)[,c("Group", "DPC","Sex" )] %>% data.frame(),
         main = "Chd8 genotype effect, Dev stage-corrected,  clipped (limma-trend)")
```

Heatmap for all the FDR < 0.05 genes (there are `r nrow(topTable(limmavoomTMM, number = Inf, coef = "GroupMu", sort.by = "p", p.value = 0.05))` by limma-trend:

```{r adjhm.clip.more, fig.height = 6, fig.width = 10}
breaksList = seq(-3, 3, by = 6/length(bcols))

pheatmap(dadjG %>% data.frame() %>%
           dplyr::filter(rownames(sumexpG) %in% rownames(topTable(limmavoomTMM, number = Inf, 
                                                                  p.value = 0.05,
                                                                  coef = "GroupMu", 
                                                                  sort.by = "p"))),
         scale="row", breaks = breaksList, show_rownames = FALSE,
         cluster_rows = TRUE, cluster_cols = FALSE, color = bcols, border_color = NA,
           annotation_col = colData(sumexpG)[,c("Group", "DPC","Sex" )] %>% data.frame(),
         main = "Chd8 genotype FDR < 0.05, Dev stage-corrected, clipped (limma-trend)")
```


# Comparing methods

Now that we've run `r ncol(difmethods)` different approaches to test each gene for differences in expression by Group (Chd8 mutant vs WT), let's finally compare the results!

Do all methods find the Chd8 gene as significant (FDR < 0.05, with FDR estimated by q-value)?

```{r}
# compute qvals
difqval <- apply(difmethods, 2, function(x) qvalue(x)$qvalue)

difqval["Chd8",]
```
Yes! Though the p-values for DESeq2 and edgeR-LRT are much smaller than the rest.

Now, let's examine the overall p-value distributions for each approach to make sure they all look well-behaved.

```{r}
difmethods %>%
  pivot_longer(names_to = "Method", values_to = "p-value", cols = everything()) %>%
  ggplot(aes(x = `p-value`, group = Method)) +
  geom_histogram(bins = 50) +
  facet_wrap(~ Method)
```

They all look reasonable; no obvious cause for concern. 

Next, here's a plot of pair-wise comparisons of p-values (-log10). To avoid warnings, we remove genes that have missing values.

```{r comparemethods, fig.width = 12, fig.height = 12}
-log10(difmethods) %>% 
  drop_na() %>%
  ggpairs(lower = list(continuous = wrap("points", alpha = 0.2, size = 0.1)))
```
We can see that some methods have extremely high (Pearson) correlation (e.g. lm on logCPM and limma on logCPM), and others a bit lower (e.g. limma-voom and DESeq2).

Here we make a heatmap of Spearman correlations among methods. Clustering of rows and columns as want to see what's similar to what.

```{r}
mcor <- cor(difmethods, method="spear", use="pair")
pheatmap(mcor, color = bcols)
```

Interestingly, it seems there are three main groupings: (1) limma-voom approaches, (2) the other limma approaches (original and trend) along with regular lm, and (3) DESeq2 and edgeR approaches.

Let's examine the agreement of the top genes (FDR < 0.05), with FDR estimated by q-value.

```{r, fig.width = 10, fig.height = 6}
# get genes qval < 0.05
topGenes <- apply(difqval, 2, function(x) row.names(difqval[x < 0.05,]))

# Counts for each method
unlist(lapply(topGenes, length))

# Upset plot
upset(fromList(topGenes), nsets = 8, order.by = "freq")
```

We see that `DESeq2` finds the highest number of significant genes, and `limma` on logCPM values finds the fewest. There is a large set of genes that all methods call significant. 

There are plenty of other ways we could evaluate the similarities and differences of the results, or drill into details, but this is good enough to give a sense.

General observations:

* Overall agreement among methods is quite good, especially for the top genes.
* Most significant p-values from edgeR (LR) and DESeq2 are much smaller than for other methods (not that you should seriously believe p-values like 10^-30).
* limma-trend didn't perform much differently than regular limma, possibly because of the wide range of depths among samples (greater than 4-fold difference).
* Variations of approach within methods doesn't make a massive difference (e.g. voom with or without norm factors)

## Differences between limma-trend and limma-voom

While things look very similar overall, we should be curious about the genes that the methods disagree about. Let's examine the gene ranks between limma-trend and limma-voom.

```{r disagreements}
# This is a zoom in on just two methods.
plot(rank(difmethods[,"limmatrend"]), rank(difmethods[,"limmavoom"]), pch=20, cex=0.4,)
```

We'll isolate genes which rank high in limma-voom but low in limma-trend: ranked in top 10 of limma-voom, but not in top 1000 of limma-trend.

```{r}
difranks <- apply(difmethods, 2, rank)

disg <- row.names(difmethods)[which( difranks[,"limmavoom"] < 10 & 
                                     difranks[,"limmatrend"] > 1000)]

# these "hits" are specific to voom.
signif(difmethods[disg,], 3)
difranks[disg,]

```

What do these genes look like?

```{r}
# get counts in tidy format
counts_long <- assays(sumexp)$counts %>% data.frame() %>%
  rownames_to_column("Gene") %>%
  pivot_longer(names_to = "Sample", values_to = "Count", cols = -Gene) %>%
  left_join(data.frame(colData(sumexp)), by="Sample")

counts_long %>% 
  filter(Gene %in% disg) %>%
  ggplot(aes(x = Group, y = Count, colour = Group)) +
  geom_jitter(width=0.05, height=0, size=3 )  + 
  facet_grid(Gene ~ DPC) + 
  ggtitle("limma-voom only genes (counts)") + 
  labs(x="Group" ) + 
  geom_hline(yintercept = log2(1), color="grey")
```

*Conclusions:* Each of these three genes being among the top hits for limma-voom looks fishy. Except for adults, they are is barely expressed (0-4 raw counts vs ~500). Maybe we'd like to see this gene come up if we were looking for interaction effects. 

Why does this happen? For voom the weighting means that very low expression values are going to have little effect on the model fit. Inspecting the weights (`vw[disg,]$weights`) they are about 30-40x higher for the adults.

Whether you think Etnppl, Plin4, and Xdh are false positives or not could be a matter of opinion (we don't know the ground truth), but one lesson is: before getting excited about any particular result, look at the data!
